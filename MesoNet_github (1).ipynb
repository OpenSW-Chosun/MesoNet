{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNrNf7+jqG+w5xAuGdPJ1TW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **<h1>필요 라이브러리 설치</h1>**\n","\n"],"metadata":{"id":"xMySo9j3KN7J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KH7DhEXTKH_f","collapsed":true},"outputs":[],"source":["!pip install tensorflow opencv-python dlib\n","!pip install torch torchvision\n","!pip install opencv-python\n","!pip install tensorflow keras opencv-python\n","\n","!pip install tensorflow==2.8.0 keras==2.8.0\n","\n","# 사용 모델\n","!git clone https://github.com/DariusAf/MesoNet.git \"/content/drive/MyDrive/Colab Notebooks/OpenSourceProject/MesoNet_model\""]},{"cell_type":"markdown","source":["# **<h1> 드라이브 마운트 </h1>**"],"metadata":{"id":"gSRHyy6DKmel"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/OpenSourceProject/MesoNet_model\n","# %cd /content/drive/MyDrive/Colab Notebooks/OpenSourceProject/MesoNet/sample_viedo\n","\n","!pwd"],"metadata":{"id":"avv9zc2mKmBX","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from classifiers import Meso4\n","\n","# Meso4 모델 생성\n","model = Meso4()\n","\n","# 가중치 로드 (확장자 h5 확인)\n","model.load('weights/Meso4_DF.h5')\n","\n","# 이미지 전처리 함수 정의\n","def preprocess_image(image_path):\n","    image = cv2.imread(image_path)  # 이미지 읽기\n","    image = cv2.resize(image, (IMGWIDTH, IMGWIDTH))  # 모델에 맞게 크기 조정\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB로 변환\n","    image = np.array(image) / 255.0  # 정규화\n","    image = np.expand_dims(image, axis=0)  # 배치 차원 추가\n","    return image\n"],"metadata":{"id":"RbD9mU5qEyuJ","executionInfo":{"status":"ok","timestamp":1730459941980,"user_tz":-540,"elapsed":727,"user":{"displayName":"박준언","userId":"06740159432376359304"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# 이미지 크기 정의\n","IMGWIDTH = 256\n","\n","# 동영상 경로 설정\n","video_path = '/content/drive/MyDrive/Colab Notebooks/OpenSourceProject/sample_viedo/aassnaulhq.mp4'\n","\n","# 비디오 파일 열기\n","cap = cv2.VideoCapture(video_path)\n","\n","# 프레임을 모델에 넣기 위한 전처리 함수\n","def preprocess_frame(frame):\n","    frame = cv2.resize(frame, (IMGWIDTH, IMGWIDTH))  # 크기 조정\n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # RGB로 변환\n","    frame = np.array(frame) / 255.0  # 정규화\n","    frame = np.expand_dims(frame, axis=0)  # 배치 차원 추가\n","    return frame\n","\n","# 동영상에서 프레임 추출 및 예측\n","frame_count = 0\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # 특정 간격마다 프레임을 선택 (예: 30 프레임마다)\n","    if frame_count % 30 == 0:\n","        processed_frame = preprocess_frame(frame)\n","        prediction = model.predict(processed_frame)[0][0]\n","\n","        # 결과 출력\n","        print(f\"Frame {frame_count}: Prediction = {prediction}\")\n","        if prediction > 0.5:\n","            print(\"Result: Deepfake Detected\")\n","        else:\n","            print(\"Result: Real\")\n","\n","    frame_count += 1\n","\n","# 비디오 파일 닫기\n","cap.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PifG0s6oeTgL","executionInfo":{"status":"ok","timestamp":1730460900727,"user_tz":-540,"elapsed":6252,"user":{"displayName":"박준언","userId":"06740159432376359304"}},"outputId":"7a2fae35-84b8-4510-c59a-a0eaf2b325a4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Frame 0: Prediction = 0.9498993754386902\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Frame 30: Prediction = 0.9200960993766785\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Frame 60: Prediction = 0.9779819250106812\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Frame 90: Prediction = 0.9662978053092957\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Frame 120: Prediction = 0.9055718183517456\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Frame 150: Prediction = 0.9972355365753174\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Frame 180: Prediction = 0.9975985884666443\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Frame 210: Prediction = 0.9887987971305847\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Frame 240: Prediction = 0.9964243769645691\n","Result: Deepfake Detected\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Frame 270: Prediction = 0.9807590842247009\n","Result: Deepfake Detected\n"]}]}]}